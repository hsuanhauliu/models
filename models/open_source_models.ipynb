{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b897ada-d643-4e3e-9614-90e219016397",
   "metadata": {},
   "source": [
    "# Open Source Models\n",
    "\n",
    "This notebook shows how to use open source models from popular sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc711da8-0c29-42f4-8b3a-233221794093",
   "metadata": {},
   "source": [
    "## Pytorch Hub\n",
    "\n",
    "Pre-trained open-source models from Meta: https://pytorch.org/hub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b466f2dd-51ee-4515-9778-8fb311e975b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\n",
    "# or any of these variants\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet101', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_mobilenet_v3_large', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb8a3ee-dc2a-4de8-a23c-4bf76106b3b3",
   "metadata": {},
   "source": [
    "## Hugging Face Hub\n",
    "\n",
    "The leading platform for open-source LLMs, transformers, and multimodal models: https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd5f581-399b-4e59-b2b8-ffeb6345fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Model ID for a sentiment analysis model\n",
    "model_id = \"ProsusAI/finbert\"\n",
    "\n",
    "# Load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "\n",
    "# print(f\"Model loaded: {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b8101c-91b2-4857-878a-b8779db68629",
   "metadata": {},
   "source": [
    "## ONNX Model Zoo\n",
    "\n",
    "A collection of pre-trained, state-of-the-art models in the ONNX format: https://github.com/onnx/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44ad07c-3c7d-47eb-a43c-25fcf22af161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Example: Download a pre-trained SqueezeNet model (simplified URL for demonstration)\n",
    "model_url = \"https://github.com/onnx/models/raw/main/vision/classification/squeezenet/model/squeezenet1.0-3.onnx\"\n",
    "model_path = \"squeezenet.onnx\"\n",
    "if not os.path.exists(model_path):\n",
    "    print(\"Downloading ONNX model...\")\n",
    "    response = requests.get(model_url, stream=True)\n",
    "    with open(model_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# Load the ONNX model session\n",
    "ort_session = ort.InferenceSession(model_path)\n",
    "\n",
    "# Prepare dummy input data (e.g., a batch of 1 image, 3 channels, 224x224)\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "dummy_input = np.random.randn(1, 3, 224, 224).astype(np.float32)\n",
    "\n",
    "# Run inference\n",
    "output = ort_session.run(None, {input_name: dummy_input})\n",
    "# print(f\"Output shape: {output[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797972c6-4b36-4658-beae-7d8bbf75da9f",
   "metadata": {},
   "source": [
    "## Kaggle\n",
    "\n",
    "Community contributed open source models and datasets: https://www.kaggle.com/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2f2a65-92e5-48fb-99b8-46f61eacc0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Ensure you have the Kaggle API key set up (usually via ~/.kaggle/kaggle.json)\n",
    "\n",
    "# Model handle format: {owner_slug}/{model_slug}/{framework}/{variation_slug}\n",
    "model_handle = \"google/gemma/pyTorch/2b\"\n",
    "\n",
    "# Download the model and get the local path\n",
    "path = kagglehub.model_download(model_handle)\n",
    "\n",
    "print(f\"Model files downloaded to: {path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
